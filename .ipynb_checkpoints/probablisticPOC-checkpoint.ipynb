{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a42103b-47be-40e3-9d64-13d4595d50c6"
   },
   "source": [
    "# Probablistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xxml3fXzxIul",
    "outputId": "d8d043c3-1921-47d7-a781-7295be4bffcf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "678db546-b1d7-43ac-b907-cf30cf664d5b",
    "outputId": "515be02c-93e3-4b79-bda7-0f466e333f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[tune] in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (1.10.0)\n",
      "Requirement already satisfied: filelock in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.0.12)\n",
      "Requirement already satisfied: jsonschema in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.2.0)\n",
      "Requirement already satisfied: pyyaml in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (5.3)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.44.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (3.19.4)\n",
      "Requirement already satisfied: redis>=3.5.0 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (4.1.4)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (7.0)\n",
      "Requirement already satisfied: numpy>=1.16; python_version < \"3.9\" in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.21.6)\n",
      "Requirement already satisfied: attrs in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (19.3.0)\n",
      "Requirement already satisfied: pandas; extra == \"tune\" in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (1.0.1)\n",
      "Requirement already satisfied: requests; extra == \"tune\" in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (2.26.0)\n",
      "Requirement already satisfied: tabulate; extra == \"tune\" in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from ray[tune]) (0.8.9)\n",
      "Collecting tensorboardX>=1.9; extra == \"tune\"\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyrsistent>=0.14.0 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[tune]) (0.15.7)\n",
      "Requirement already satisfied: setuptools in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[tune]) (46.0.0.post20200309)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[tune]) (1.5.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from jsonschema->ray[tune]) (1.14.0)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n",
      "Requirement already satisfied: packaging>=20.4 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from redis>=3.5.0->ray[tune]) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from pandas; extra == \"tune\"->ray[tune]) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from pandas; extra == \"tune\"->ray[tune]) (2019.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from requests; extra == \"tune\"->ray[tune]) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from requests; extra == \"tune\"->ray[tune]) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from requests; extra == \"tune\"->ray[tune]) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from requests; extra == \"tune\"->ray[tune]) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->ray[tune]) (2.2.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.11.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jimmyouyang/anaconda3/lib/python3.7/site-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (2.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install ray[tune]\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from Training import model, utils, dataset, train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "defc55b7-af20-44be-90f1-f39f0853dd38"
   },
   "outputs": [],
   "source": [
    "def check_acc(y_hat,y,margin=0.05):\n",
    "    a_err = (np.abs(y_hat - y)) # get normalized error \n",
    "    err = np.divide(a_err, y, out=a_err, where=y==0)\n",
    "    assert(err.shape == y.shape)\n",
    "    num_correct = 0\n",
    "    for row in err:\n",
    "        num_in_row = len(np.where(row < margin)[0]) # margin * 100 because \n",
    "        if num_in_row == len(row):\n",
    "            num_correct += 1\n",
    "\n",
    "    num_samples = y.shape[0]\n",
    "    correct_idx = np.where(err < margin)\n",
    "    num_part_correct = len(correct_idx[0])\n",
    "    num_part_samples = y.shape[0] * y.shape[1]\n",
    "    print(f\"Correct = {num_correct} / {num_samples}\")\n",
    "    return (num_correct/num_samples)\n",
    "from matplotlib.patches import Ellipse\n",
    "def multivariate_gaussian_nll(ypreds, ytrue, var):\n",
    "    \n",
    "    diag = torch.exp(var[:,:2]) # convert log-scale var to\n",
    "    n = ypreds.shape[1] #number of parameters ie number of means (2 gain and bandwidth)\n",
    "    B = ypreds.shape[0] #Batch size\n",
    "    \n",
    "    z = torch.zeros(B)\n",
    "    o = torch.ones(B)\n",
    "    D = torch.stack((diag[:,0],z,z,diag[:,1]),dim=1).reshape(B,2,2) # form Diagnol matrix D for LDLT\n",
    "    L = torch.stack((o,z,var[:,2],o),dim=1).reshape(B,2,2) # form L matrix \n",
    "    LT = torch.stack((o,var[:,2],z,o),dim=1).reshape(B,2,2) # form LT matrix (transpose of L)\n",
    "\n",
    "    sigma = L @ D @ LT   # form sigma inv from LDLT decomp\n",
    "    ximu =(ytrue-ypreds).reshape(B,2,1)  #true- minus \n",
    "    ximuT =(ytrue-ypreds).reshape(B,1,2) # true- minus  transpose\n",
    "\n",
    "    loss = 0.5*torch.mean(ximuT@sigma@ximu + ((n/2)*(-torch.sum(var[:,:2],axis=1).reshape(B,1))))\n",
    "    return loss\n",
    "def formCovMatrix(var):\n",
    "    diag = np.exp(var[:2])\n",
    "    z = np.zeros(2)\n",
    "    o = np.ones(2)\n",
    "    D = np.array([diag[0],0,0,diag[1]]).reshape(2,2)\n",
    "    L = np.array([1,0,var[2],1]).reshape(2,2)\n",
    "    LT = np.array([1,var[2],0,1]).reshape(2,2)\n",
    "    sigma = L @ D @ LT\n",
    "    return np.linalg.pinv(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7398448-40f9-4c10-afb8-69a8444511c0"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2d2858d-a42f-48f6-9de3-d26d88247ccc"
   },
   "outputs": [],
   "source": [
    "data_raw = utils.parseGainAndBWCsv2(\"Data/BW-3000.csv\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53cbbc10-eb8d-490a-848c-23832f79bc18",
    "outputId": "81145d66-9a1a-4e1a-8fff-933c09c09fd1"
   },
   "outputs": [],
   "source": [
    "print(data_raw.min(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85d7ae70-e420-4c5f-8712-a0dc166fb873"
   },
   "source": [
    "##### Split data into inputs X and target Y Normalize to [0,1] (inclusive) and create Training and Testign Splits.  \n",
    "Save scaler to denormalize data later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd2625d6-6c84-44b0-9b60-68e46eeb41b1"
   },
   "outputs": [],
   "source": [
    "data = preprocessing.MinMaxScaler((0,1)).fit_transform(data_raw)\n",
    "scaler = preprocessing.MinMaxScaler((0,1))\n",
    "data2 = scaler.fit_transform(data_raw)\n",
    "assert(np.allclose(data,data2))\n",
    "X = data[:,:2]\n",
    "Y = data[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25750082-6130-442e-929d-67ce5e824bb7"
   },
   "source": [
    "#### Define Model and Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de2c611a-c7f2-4170-94af-4d2025de4f27"
   },
   "source": [
    "##### Define model\n",
    "\n",
    "* Model: MLP with variable hidden layer number and width  \n",
    "* Output layer: \n",
    "    * Node 1 and 2 are the mean for probability mean \n",
    "    * Node 3-5 are values of the covariance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3618fa3-b062-454c-a941-d2d8783d52cc"
   },
   "outputs": [],
   "source": [
    "test_model = model.DistModelBatchNorm(2,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4438de8d-1aae-4213-b15a-f70a13b80002"
   },
   "source": [
    "##### Define Loss\n",
    "\n",
    "* Loss: guassian_nll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "149403d4-2f8c-4238-9cb0-8c7ae7d36a95"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adagrad(test_model.parameters(),lr=0.001)\n",
    "loss_fn = multivariate_gaussian_nll\n",
    "\n",
    "dataset1 = dataset.CircuitSynthesisGainAndBandwidthManually(Y, X)\n",
    "train_dataset, val_dataset = utils.splitDataset(dataset1, 0.95)\n",
    "    \n",
    "train_data = DataLoader(train_dataset,batch_size = 500)\n",
    "validation_data = DataLoader(val_dataset, batch_size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8827726e-cbf1-4d93-8aea-51d8bfe01a5f",
    "outputId": "fd70aed1-9cbf-4975-cc33-c858167182e8"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "loss_list, val_loss_list = train.trainProbModel(test_model, train_data, loss_fn, optimizer, num_epochs=epochs, print_every=10, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e63a3d25-06d6-4681-82ba-48c01b68b214"
   },
   "source": [
    "## Loss visualization\n",
    "\n",
    "Loss plots for training and validation by epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37224eee-48eb-410f-80de-6a349dbd8ab2"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(loss_list)),loss_list)\n",
    "plt.plot(np.arange(len(val_loss_list)),val_loss_list)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Guassian NLL')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64a54df1-4c4b-4c23-bfa5-43c07a8b2479"
   },
   "source": [
    "## Testing scipt\n",
    "\n",
    "My idea of the testing script. \n",
    "It takes the inverse simulator prediction (Y -> X^)  \n",
    "Pass X^ to mock_simulator to get Y^   \n",
    "evaluate performance from Y to Y^  \n",
    "I don't know if the data is being shuffled at all could contribute too the poor performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16763cec-b702-4c43-bd3a-1a9dfcb69d4d",
    "outputId": "39cc254a-261a-46d2-d324-c4894acf1728"
   },
   "outputs": [],
   "source": [
    "x_preds = test_model(torch.Tensor(Y))\n",
    "mock_simulator = tf.keras.models.load_model('mock_simulator2.0')\n",
    "print(x_preds.shape)\n",
    "means = x_preds.detach().numpy()[:,:2]\n",
    "final_preds = mock_simulator(means).numpy()    \n",
    "# for i,d in enumerate(final_preds):\n",
    "#     print(Y[i],d)\n",
    "print(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JN3bR19BngQq",
    "outputId": "59098b1f-2cd7-4296-b2c6-f4a47ebb5238"
   },
   "outputs": [],
   "source": [
    "check_acc(X,means,margin=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaY-QusQ9nNa"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb496032-fc33-4026-9dc8-3dcaccf78ef0",
    "outputId": "ba36f6b8-2647-4bd7-f78a-db841b506e47"
   },
   "outputs": [],
   "source": [
    "check_acc(Y,final_preds,margin=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihaJv6mYSqyF"
   },
   "outputs": [],
   "source": [
    "values = x_preds.detach().numpy()\n",
    "C = np.ones((values.shape[0],1,3))\n",
    "for i,c in enumerate(C):\n",
    "    c[:,1] = X[i,0] / X[:,0].max()\n",
    "    c[:,2] = X[i,1] / X[:,1].max()\n",
    "C = C.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "206742c1-3705-4dd8-9c1d-74ebffea17e3",
    "outputId": "4a50b14b-d322-4eb9-c52f-98cc568b2afe"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(36, 12))\n",
    "axes.get_xaxis().set_visible(False) # remove erroreas graph axis\n",
    "axes.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "xlim = [Y[:,0].min(),Y[:,0].max()]\n",
    "ylim = [Y[:,1].min(),Y[:,1].max()]\n",
    "\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "plt.scatter(Y[:,0],Y[:,1], c=C)\n",
    "ax = fig.add_subplot(122)\n",
    "#ax.set_xlim(xlim)\n",
    "#ax.set_ylim(ylim)\n",
    "plt.scatter(final_preds[:,0],final_preds[:,1], c=C)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fa90242-bc69-4619-bef0-a177e38f4fdb"
   },
   "outputs": [],
   "source": [
    "def getCovEllip(cov,pos):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "    theta = np.linspace(0, 2*np.pi, 1000);\n",
    "    ellipsis = (np.sqrt(eigenvalues[None,:]) * eigenvectors) @ [np.sin(theta), np.cos(theta)] + pos.reshape(2,1)\n",
    "    return ellipsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "a9a821e7-d5e1-477a-bc3a-0b4d63cfde4b",
    "outputId": "3c68338b-421b-4e11-a9a6-389d5d284597"
   },
   "outputs": [],
   "source": [
    "pred_means = x_preds.detach().numpy()[:,:2] # get meansd \n",
    "\n",
    "values = x_preds.detach().numpy()\n",
    "fig, axes = plt.subplots(figsize=(24, 24))\n",
    "axes.get_xaxis().set_visible(False) # remove erroneos graph axis\n",
    "axes.get_yaxis().set_visible(False)\n",
    "\n",
    "xlim = [X[:,0].min(),X[:,0].max()] # calculate limits for input data to set plot axis\n",
    "ylim = [X[:,1].min(),X[:,1].max()]\n",
    "\n",
    "num_ellipse = 50\n",
    "ellipses = []\n",
    "for i in range(num_ellipse):\n",
    "    i = np.random.randint(values.shape[0])\n",
    "    cov = values[i,2:]\n",
    "    pos = values[i,:2]\n",
    "    cov = formCovMatrix(cov)\n",
    "    ellipses.append(getCovEllip(cov,pos))\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "plt.scatter(X[:,1],X[:,0], c=C)\n",
    "ax = fig.add_subplot(222)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "plt.scatter(pred_means[:,1],pred_means[:,0], c=C)\n",
    "ax = fig.add_subplot(224)\n",
    "plt.scatter(pred_means[:,1],pred_means[:,0], c=C)\n",
    "for ellipse in ellipses:\n",
    "    plt.plot(ellipse[1,:], ellipse[0,:],\"g\")\n",
    "ax = fig.add_subplot(223)\n",
    "plt.scatter(X[:,1],X[:,0], c=C)\n",
    "for ellipse in ellipses:\n",
    "    plt.plot(ellipse[1,:], ellipse[0,:],\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxC1O8ZHIuIs"
   },
   "source": [
    "## Load Best Model\n",
    "Open Saved model run on all data.  \n",
    "Denomalize data parameter predictions for testing with cadence simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b-_VGHkYIta8",
    "outputId": "b6ecd73c-c6b2-41aa-a9aa-c6bd6ff76b61"
   },
   "outputs": [],
   "source": [
    "test_model = model.DistModelBatchNorm(2,5)\n",
    "test_model.load_state_dict(torch.load(\"99acc-batchnorm-relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSCWMiByzy0I"
   },
   "outputs": [],
   "source": [
    "stack = np.hstack((final_preds,Y))\n",
    "print(stack.shape)\n",
    "denorm_data = scaler.inverse_transform(stack)\n",
    "print(denorm_data)\n",
    "print(denorm_data.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMu3Ph3hyswQ"
   },
   "outputs": [],
   "source": [
    "deX = denorm_data[:,:2]\n",
    "raw_X = data_raw[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCB0WCN58-rQ"
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"predictions\", denorm_data[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jhBcJzv9neQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.DataFrame(denorm_data[:,:2]).to_csv(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "probablisticPOC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
